{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e01f98a",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f95f38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_selector , make_column_transformer , ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "\n",
    "def load_housing_data():\n",
    "    tarball_path = Path(\"datasets/housing.tgz\")\n",
    "    if not tarball_path.is_file():\n",
    "        Path(\"datasets\").mkdir(parents=True , exist_ok=True)\n",
    "        url = \"https://github.com/ageron/data/raw/main/housing.tgz\"\n",
    "        urllib.request.urlretrieve(url , tarball_path)\n",
    "        with tarfile.open(tarball_path) as housing_tarball:\n",
    "            housing_tarball.extractall(path=\"datasets\" , filter=\"data\")\n",
    "    return pd.read_csv(Path(\"datasets/housing/housing.csv\"))\n",
    "\n",
    "housing_full = load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fadaffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create income category attribute\n",
    "housing_full[\"income_cat\"] = pd.cut(housing_full[\"median_income\"] , \n",
    "                                   bins=[0 , 1.5 , 3.0 , 4.5 , 6 , np.inf],\n",
    "                                   labels=[1 , 2 , 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbd92dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into training and test set based on income category (stratified) ; 20% test set\n",
    "strat_train_set , strat_test_set = train_test_split(housing_full , test_size=0.2 , \n",
    "                                                    stratify=housing_full[\"income_cat\"] , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40241258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of \"income_cat\" because we don't need it again\n",
    "for set_ in (strat_train_set , strat_test_set):\n",
    "    set_.drop(\"income_cat\" , axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "526ec874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate data to predictor and labels (in training set)\n",
    "housing = strat_train_set.drop(\"median_house_value\" , axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "687f4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterSimilarity(BaseEstimator , TransformerMixin):\n",
    "    def __init__(self , n_clusters=10 , gamma=1.0 , random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self , X , y=None , sample_weight=None):\n",
    "        self.kmeans_ = KMeans(self.n_clusters , random_state=self.random_state)\n",
    "        self.kmeans_.fit(X , sample_weight=sample_weight)\n",
    "        return self #always return self!\n",
    "    \n",
    "    def transform(self , X):\n",
    "        return rbf_kernel(X , self.kmeans_.cluster_centers_ , gamma=self.gamma)\n",
    "    \n",
    "    def get_feature_names_out(self , names=None):\n",
    "        return [f\"Cluster {i} similarity\" for i in range(self.n_clusters)]  \n",
    "        \n",
    "\n",
    "def column_ratio(X):\n",
    "    \"\"\"Calculates the ratio of 2 given columns\"\"\"\n",
    "    return X[: , [0]] / X[: , [1]]\n",
    "\n",
    "def ratio_name(function_transformer , feature_names_in):\n",
    "    return [\"ratio\"] #feature names out\n",
    "\n",
    "def ratio_pipeline():\n",
    "    return make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                        FunctionTransformer(column_ratio , feature_names_out=ratio_name),\n",
    "                        StandardScaler())\n",
    "\n",
    "log_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                            FunctionTransformer(np.log , feature_names_out=\"one-to-one\"),\n",
    "                            StandardScaler())\n",
    "\n",
    "cluster_simil = ClusterSimilarity(n_clusters=10 , gamma=1 , random_state=42)\n",
    "\n",
    "default_num_pipeline = make_pipeline(SimpleImputer(strategy=\"median\"),\n",
    "                                    StandardScaler())\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"bedrooms\" , ratio_pipeline() , [\"total_bedrooms\" , \"total_rooms\"]),\n",
    "    (\"rooms_per_house\" , ratio_pipeline() , [\"total_rooms\" , \"households\"]),\n",
    "    (\"people_per_house\" , ratio_pipeline() , [\"population\" , \"households\"]),\n",
    "    (\"log\" , log_pipeline , [\"total_bedrooms\" , \"total_rooms\" , \"population\" , \"households\" , \"median_income\"]),\n",
    "    (\"geo\" , cluster_simil , [\"latitude\" , \"longitude\"]),\n",
    "    (\"cat\" , cat_pipeline , make_column_selector(dtype_include=object))\n",
    "],\n",
    "remainder=default_num_pipeline) #remaining column: housing_median_age\n",
    "\n",
    "\n",
    "housing_prepared = preprocessing.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "076d0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning with RandomForestRegressor using randomized search for best hyperparams\n",
    "full_pipeline_rfr = Pipeline([\n",
    "    (\"preprocessing\" , preprocessing),\n",
    "    (\"random_forest\" , RandomForestRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "param_distr = {'preprocessing__geo__n_clusters' : randint(low=3 , high=50),\n",
    "              'random_forest__max_features' : randint(low=2 , high=20)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(full_pipeline_rfr , param_distributions=param_distr , \n",
    "                                n_iter=10 , cv=3 , scoring='neg_root_mean_squared_error' ,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f6b447c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning with RandomForestRegressor using randomized search for best hyperparams and SelectFromModel\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "full_pipeline_rfr_sel = Pipeline([\n",
    "    (\"preprocessing\" , preprocessing),\n",
    "    (\"random_forest\" , SelectFromModel(estimator=RandomForestRegressor(random_state=42))),\n",
    "])\n",
    "\n",
    "param_distr = {'preprocessing__geo__n_clusters' : randint(low=3 , high=50),\n",
    "              'random_forest__max_features' : randint(low=2 , high=20)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(full_pipeline_rfr , param_distributions=param_distr , \n",
    "                                n_iter=10 , cv=3 , scoring='neg_root_mean_squared_error' ,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "795608fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning with support vector machine regressor (SVR)\n",
    "#first using gridserach\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "full_pipeline_svr = Pipeline([\n",
    "    (\"preprocessing\" , preprocessing),\n",
    "    (\"svm_regressor\" , SVR()),\n",
    "])\n",
    "\n",
    "#param grid uses both kernels for a more compact notation and for better comparison\n",
    "param_grid = [{\"svm_regressor__kernel\" : [\"linear\"] ,\n",
    "               \"svm_regressor__C\" : [10 , 50 , 100 , 500 , 1000 , 5000]},\n",
    "              \n",
    "              {\"svm_regressor__kernel\" : [\"rbf\"] ,\n",
    "              \"svm_regressor__C\" : [10 , 50 , 100 , 500 , 1000 , 5000] ,\n",
    "              \"svm_regressor__gamma\" : [0.01 , 0.05 , 0.1 , 0.5 , 1 , 5]}\n",
    "             ]\n",
    "\n",
    "grid_search_svm = GridSearchCV(full_pipeline_svr , param_grid,\n",
    "                               cv=3 , scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c2bc16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using RandomizedSearchCV\n",
    "from scipy.stats import expon, loguniform\n",
    "\n",
    "param_dist = {\n",
    "        'svm_regressor__kernel': ['linear', 'rbf'],\n",
    "        'svm_regressor__C': loguniform(20, 200_000),\n",
    "        'svm_regressor__gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "rnd_search_svm = RandomizedSearchCV(full_pipeline_svr , param_distributions=param_dist,\n",
    "                               n_iter=10 , cv=3 , scoring=\"neg_root_mean_squared_error\",\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97820eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm.fit(housing , housing_labels)\n",
    "grid_search_svm_rmse = -grid_search_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4d158665",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_svm.fit(housing , housing_labels)\n",
    "rnd_search_svm_rmse = -rnd_search_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "66efe201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61951.67609348383\n",
      "53878.52706541228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svm_regressor__C': 157055.10989448498,\n",
       " 'svm_regressor__gamma': 0.26497040005002437,\n",
       " 'svm_regressor__kernel': 'rbf'}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(grid_search_svm_rmse))\n",
    "print(str(rnd_search_svm_rmse))\n",
    "rnd_search_svm.best_params_\n",
    "\n",
    "#testing model\n",
    "#X_test = strat_test_set.drop(\"median_house_value\" , axis=1)\n",
    "#y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "#final_predictions = final_model.predict(X_test)\n",
    "\n",
    "#final_rmse = root_mean_squared_error(y_test , final_predictions)\n",
    "#print(final_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "de70e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a SelectFromModel to select only the most important attributes\n",
    "select_pipeline = Pipeline([\n",
    "    (\"preprocessing\" , preprocessing),\n",
    "    (\"attrselector\" , SelectFromModel(estimator=RandomForestRegressor(random_state=42) , threshold=0.005)),\n",
    "    (\"svm_regressor\" , SVR(kernel=rnd_search_svm.best_params_[\"svm_regressor__kernel\"] , \n",
    "                          C=rnd_search_svm.best_params_[\"svm_regressor__C\"] ,\n",
    "                          gamma=rnd_search_svm.best_params_[\"svm_regressor__gamma\"]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9105d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53160.70373894 53695.62656734 56047.92108411]\n"
     ]
    }
   ],
   "source": [
    "#evaluate using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "selector_rmses = -cross_val_score(select_pipeline,\n",
    "                                  housing,\n",
    "                                  housing_labels,\n",
    "                                  scoring=\"neg_root_mean_squared_error\",\n",
    "                                  cv=3)\n",
    "print(str(selector_rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "491c590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exercise 4)\n",
    "# Creating an custom transformer which get an regressor and features to train on\n",
    "from sklearn.base import MetaEstimatorMixin, clone\n",
    "\n",
    "class FeaturesFromRegressor(BaseEstimator , TransformerMixin , MetaEstimatorMixin):\n",
    "    def __init__(self , regressor , features):\n",
    "        self.regressor = regressor\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self , X , y=None):\n",
    "        if hasattr(X , \"columns\"):\n",
    "            self.feature_names_in_ = list(X.columns)\n",
    "            X_df = X\n",
    "        else:\n",
    "            X_df = pd.DataFrame(X)\n",
    "            \n",
    "        self.input_features_ = [c for c in X.columns if c not in self.features]\n",
    "        self.regressor_ = clone(self.regressor)\n",
    "        self.regressor_.fit(X_df[self.input_features_] , X_df[self.features])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self , X):\n",
    "        columns = X.columns if hasattr(X , \"columns\") else None\n",
    "        X_df = pd.DataFrame(X , columns=columns)\n",
    "        predicts = self.regressor_.predict(X_df[self.input_features_])\n",
    "        if predicts.ndim == 1:\n",
    "            predicts.reshape(-1 , 1)\n",
    "        extra_columns = [f\"pred_{t}\" for t in self.features]\n",
    "        preds_df = pd.DataFrame(predicts , columns=extra_columns , index=X_df.index)\n",
    "        return pd.concat([X_df , preds_df] , axis=1)\n",
    "    \n",
    "    def get_feature_names_out(self , input_features=None):\n",
    "        extra_columns = [f\"pred_{t}\" for t in self.target_features]\n",
    "        return self.feature_names_in_ + extra_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5db6ac20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>median_income</th>\n",
       "      <th>pred_median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13096</th>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.42</td>\n",
       "      <td>2.0987</td>\n",
       "      <td>3.985767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>34.14</td>\n",
       "      <td>-118.38</td>\n",
       "      <td>6.0876</td>\n",
       "      <td>6.899400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3785</th>\n",
       "      <td>38.36</td>\n",
       "      <td>-121.98</td>\n",
       "      <td>2.4330</td>\n",
       "      <td>2.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14689</th>\n",
       "      <td>33.75</td>\n",
       "      <td>-117.11</td>\n",
       "      <td>2.2618</td>\n",
       "      <td>2.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20507</th>\n",
       "      <td>33.77</td>\n",
       "      <td>-118.15</td>\n",
       "      <td>3.5292</td>\n",
       "      <td>3.475633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14207</th>\n",
       "      <td>33.86</td>\n",
       "      <td>-118.40</td>\n",
       "      <td>4.7105</td>\n",
       "      <td>4.939100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13105</th>\n",
       "      <td>36.32</td>\n",
       "      <td>-119.31</td>\n",
       "      <td>2.5733</td>\n",
       "      <td>3.301550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>32.59</td>\n",
       "      <td>-117.06</td>\n",
       "      <td>4.0616</td>\n",
       "      <td>4.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19121</th>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.40</td>\n",
       "      <td>4.1455</td>\n",
       "      <td>4.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19888</th>\n",
       "      <td>37.66</td>\n",
       "      <td>-122.41</td>\n",
       "      <td>3.2833</td>\n",
       "      <td>4.250667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16512 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude  median_income  pred_median_income\n",
       "13096     37.80    -122.42         2.0987            3.985767\n",
       "14973     34.14    -118.38         6.0876            6.899400\n",
       "3785      38.36    -121.98         2.4330            2.900900\n",
       "14689     33.75    -117.11         2.2618            2.261800\n",
       "20507     33.77    -118.15         3.5292            3.475633\n",
       "...         ...        ...            ...                 ...\n",
       "14207     33.86    -118.40         4.7105            4.939100\n",
       "13105     36.32    -119.31         2.5733            3.301550\n",
       "19301     32.59    -117.06         4.0616            4.061600\n",
       "19121     34.06    -118.40         4.1455            4.145500\n",
       "19888     37.66    -122.41         3.2833            4.250667\n",
       "\n",
       "[16512 rows x 4 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for exercise 4: Try KNN regressor on our FeaturesOnRegressor transformer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3 , weights=\"distance\")\n",
    "knn_transf = FeaturesFromRegressor(knn , [\"median_income\"])\n",
    "features = housing[[\"latitude\" , \"longitude\" , \"median_income\"]]\n",
    "knn_transf.fit_transform(features , housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403645e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
